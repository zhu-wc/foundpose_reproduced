### main

Foundpose开源的代码无法复现出论文中报告的结果，原因是作者未将对应的渲染器代码开源。具体来说：在论文报告中，使用DINOv2的large-reg版本可以在IMO上实现39.6%的分数;经过复现，使用DINOv2的large版本在IMO上实现39.1%的分数.

作者提到复现分数低的原因是渲染器代码未公开，因此考虑对开源渲染器渲染出的图像（简称，模板图像）进行预处理: 注意到，测试图像的尺寸为640*480，基于CNOS分割实例的结果从中映射测试子图，用作姿态估计。而由于模板图像的尺寸固定为420*420，故需要将测试子图的尺度经双线形插值上采样到420*420。

从域适应的角度看，前者天然的高分辨率，后者是上采样后的高分辨率 --> 可能存在域不对齐的现象

`preprocess_templates.py`文件将测试图像裁减测试子图的过程进行可视化(可视化代码已经被注释，位于line 434 --> 446)。经过对比，发现CNOS外接正方形围绕中心点放大1.8倍后，大约是裁减测试子图对应的边界框（如图所示）。

统计每一个实例的全部测试子图上采样的平均倍率，运行`preprocess_templates.py`文件获取。

观察到lmo数据集中多个物体对应测试子图的上采样的倍率在3左右，因此在`maxpooling_upsample`文件中完成代码。感受野设置为3*3,执行最大池化，以降低模板的分辨率。接着，以双线形插值的方式上采样，恢复420*420的分辨率 ==> 结果：在经过预处理模板图像上，使用DINOv2的large版本在IMO上实现39.2%的分数（提高0.1%）


### 其他

Foundpose从测试图像中裁减实例子图的实现细节。CNOS输出的json文件中包括有边界框，该边界框为分割掩码的外接矩形，其构成为（x_min，y_min，width，high）

在`infer.py`文件中，通过下面的代码来获取实例掩码外接矩阵的坐标。注意，该box坐标的构成为(x_min,y_min,x_max,y_max)
```
                orig_box_amodal = AlignedBox2f( 
                    left=instance["input_box_amodal"][0],
                    top=instance["input_box_amodal"][1],
                    right=instance["input_box_amodal"][2],
                    bottom=instance["input_box_amodal"][3],
                )
```
随后，代码中根据测试图像上实例bbox的坐标，构造目标相机，再通过坐标变换矩阵完成裁减操作。具体来说：

首先，(420,420)中每一个像素的坐标经过测试图像相机内参变换到光心坐标系，并经由R和T变换到物体坐标系；
接着，变换到目标相机的光心坐标系，再变换到像素坐标系。

综上，建立起测试图像与实例子图之间在像素坐标上的对应关系，以双线性插值进行映射，完成实例子图(420,420)的构建
